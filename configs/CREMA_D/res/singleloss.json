{
  "training_params": {
    "batch_size": 32,
    "test_batch_size": 32
  },
  "dataset": {
    "norm": false,
    "return_data": {
      "video": true,
      "spectrogram": true,
      "audio": false,
      "face": false
    },
    "sampling_rate": 22050,
    "data_split": {
      "fold": 0
    }
  },
  "model": {
    "model_class": "ConcatClassifier_CREMAD_OGM_Decision_pre",
    "args": {
      "d_model": 512,
      "num_classes": 6,
      "fc_inner": 64,
      "dropout": 0.1,
      "shared_pred": true,
      "cls_type": "linear",
      "norm_decision": "standardization",
      "clip_grad": false,
      "bias_infusion": {
        "method": false
      },
    "multi_loss": {
      "multi_supervised_w": {
        "combined": 1,
        "c": 0,
        "g": 0
      }
    }
    },
    "load_ongoing": false,
    "save_dir": "Res_late_{}.pth.tar",
    "encoders": [
      {
        "model": "AClassifier_CREMAD_linearcls",
        "args": {
          "d_model": 512,
          "num_classes": 6,
          "fc_inner": 64,
          "dropout": 0.1,
          "freeze_encoder": false
        },
        "pretrainedEncoder": {
          "use": false,
          "dir": "unimodal_audio_linearcls_fold{}.pth.tar"
        }
      },
      {
        "model": "VClassifier_CREMAD_linearcls",
        "args": {
          "d_model": 512,
          "num_classes": 6,
          "fc_inner": 64,
          "dropout": 0.1,
          "freeze_encoder": false
        },
        "pretrainedEncoder": {
          "use": false,
          "dir": "unimodal_images_linearcls_fold{}.pth.tar"
        }
      }
    ]
  }
}